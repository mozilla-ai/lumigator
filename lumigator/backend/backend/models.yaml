- display_name: facebook/bart-large-cnn
  model: facebook/bart-large-cnn
  provider: hf
  website_url: https://huggingface.co/facebook/bart-large-cnn
  description: BART is a large-sized model fine-tuned on the CNN Daily Mail dataset.
  info:
    parameter_count: 406M
    tensor_type: F32
    model_size: 1.63GB
  tasks:
    - summarization:
        max_length: 142
        min_length: 56
        length_penalty: 2.0
        early_stopping: true
        no_repeat_ngram_size: 3
        num_beams: 4

- display_name: Falconsai/text_summarization
  model: Falconsai/text_summarization
  provider: hf
  website_url: https://huggingface.co/Falconsai/text_summarization
  description: A fine-tuned variant of the T5 transformer model, designed for the task of text summarization.
  info:
    parameter_count: 60.5M
    tensor_type: F32
    model_size: 242MB
  tasks:
    - summarization:
        max_length: 200
        min_length: 30
        length_penalty: 2.0
        early_stopping: true
        no_repeat_ngram_size: 3
        num_beams: 4

- display_name: facebook/m2m100_418M
  model: facebook/m2m100_418M
  provider: hf
  website_url: https://huggingface.co/facebook/m2m100_418M
  description: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It supports 100 languages. Please check the model card for more details.
  info:
    parameter_count: 418M
    model_size: 242MB
  tasks:
    - translation:

- display_name: facebook/m2m100_1.2B
  model: facebook/m2m100_1.2B
  provider: hf
  website_url: https://huggingface.co/facebook/m2m100_1.2B
  description: M2M100 is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation. It supports 100 languages. Please check the model card for exact list.
  info:
    parameter_count: 1.2B
    model_size: 4.96GB
  tasks:
    - translation:

- display_name: Helsinki-NLP/opus-mt
  model: Helsinki-NLP/opus-mt
  provider: hf
  website_url: https://huggingface.co/docs/transformers/en/model_doc/marian
  description: Helsinki-NLP Opus-MT models include both multilingual and bilingual translation models with support forover 290 languages. Please check the respective model card for details.
  info:
    parameter_count: 67M
    model_size: 298MB
  tasks:
    - translation:

- display_name: bigscience/mt0-base
  model: bigscience/mt0-base
  provider: hf
  website_url: https://huggingface.co/bigscience/mt0-base
  description: mT0-base is a multilingual encoder-decoder model finetuned on the xP3 dataset. It supports zero-shot cross-lingual generalization for tasks in multiple languages. Please check the model card for exact list.
  info:
    parameter_count: 582M
    tensor_type: F32
    model_size: 2.3GB
  tasks:
    - translation:

- display_name: bigscience/mt0-large
  model: bigscience/mt0-large
  provider: hf
  website_url: https://huggingface.co/bigscience/mt0-large
  description: mT0-large is a multilingual encoder-decoder model finetuned on the xP3 dataset. It supports zero-shot cross-lingual generalization for tasks in multiple languages. Please check the model card for exact list.
  info:
    parameter_count: 1.23B
    tensor_type: F32
    model_size: 4.93GB
  tasks:
    - translation:

- display_name: bigscience/mt0-xl
  model: bigscience/mt0-xl
  provider: hf
  website_url: https://huggingface.co/bigscience/mt0-xl
  description: mT0-xl is a multilingual encoder-decoder model finetuned on the xP3 dataset. It supports zero-shot cross-lingual generalization for tasks in multiple languages. Please check the model card for exact list.
  info:
    parameter_count: 3.7B
    tensor_type: F32
    model_size: 14.5GB
  tasks:
    - translation:

- display_name: gpt-4o-mini
  model: gpt-4o-mini
  provider: openai
  website_url: https://platform.openai.com/docs/models#gpt-4o-mini
  description: OpenAI's GPT-4o-mini model.
  requirements:
    - api_key
  tasks:
    - summarization:
    - translation:

- display_name: gpt-4o
  model: gpt-4o
  provider: openai
  website_url: https://platform.openai.com/docs/models#gpt-4o
  description: OpenAI's GPT-4o model.
  requirements:
    - api_key
  tasks:
    - summarization:
    - translation:

- display_name: deepseek-R1
  model: deepseek-reasoner
  provider: deepseek
  website_url: https://deepseek.ai/
  description: DeepSeek's R1 model, hosted by deepseek
  requirements:
    - api_key
  tasks:
    - summarization:
    - translation:

- display_name: deepseek-V3
  model: deepseek-chat
  provider: deepseek
  website_url: https://deepseek.ai/
  description: DeepSeek's V3 model, hosted by deepseek
  requirements:
    - api_key
  tasks:
    - summarization:
    - translation:

- display_name: ministral-8b
  model: ministral-8b-latest
  provider: mistral
  website_url: https://mistral.ai/technology/#models
  description: Mistral's 8B model, hosted by mistral
  requirements:
    - api_key
  tasks:
    - summarization:
    - translation:

- display_name: Llamafile/Mistral-7B-Instruct-v0.2
  model: mistralai/Mistral-7B-Instruct-v0.2
  provider: llamafile
  base_url: http://localhost:8080/v1
  website_url: https://huggingface.co/Mozilla/Mistral-7B-Instruct-v0.2-llamafile
  description: A llamafile package of Mistral's 7B Instruct model. Assumes that llamafile is running on the same system where the Ray cluster is located.
  info:
    parameter_count: 7.24B
    tensor_type: BF16
    model_size: 14.5GB
  requirements:
    - llamafile
  tasks:
    - summarization:
    - translation:
