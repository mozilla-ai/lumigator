{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Deepseek Models using Lumigator ðŸŠ\n",
    "\n",
    "There's been a lot of hype around [Deepseek R-1](https://github.com/deepseek-ai/DeepSeek-R1): \n",
    "it's an open source model that rivals GPT-4 performance!\n",
    "\n",
    "In this notebook, we will use Lumigator in order to evaluate Deepseek R-1 against GPT-4o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Neither GPT-4o or DeepSeek R-1 have published exactly what data they've used for training. This means\n",
    "that anything on the internet may have been used in its training and we have no way to verify that \n",
    "any public data wasn't used in the training process. This makes any evaluation we do with public data\n",
    "inherently flawed. If we post it on the internet, it's technically possible to use for LLM training and\n",
    "is no longer a reliable benchmark for future models. \n",
    "\n",
    "That's a big caveat to this notebook demonstration: the model performance differences don't actually \n",
    "indicate which model is better, in order to answer that question you'll have to try it on your own data\n",
    "that couldn't possibly have been used for training DeepSeek R-1 or GPT-4o!\n",
    "\n",
    "With that in mind, the dataset we'll use here is called [SummScreen](https://arxiv.org/abs/2104.07091) ForeverDreaming.\n",
    "It's a dataset of TV show transcripts and their associated recaps. It's useful here for a few reasons:\n",
    "\n",
    "1. The input transcripts are quite long (>8k tokens) which means that generating a summary is no trivial task.\n",
    "2. For the purposes of this demo, we'll filter down to only Gilmore Girls episodes. \n",
    "   I'm a domain expert in this because I've watched most episodes a few times, so I can judge how good the summary is, in addition to the automatic metrics we get back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The filtered test split contains 12 examples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a66fc2ab03474aa83da1bcbce644c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "653430"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# First step, let's prepare the dataset!\n",
    "\n",
    "# First, grab the dataset off huggingface: https://huggingface.co/datasets/YuanPJ/summ_screen\n",
    "ds = load_dataset(\"YuanPJ/summ_screen\", \"fd\")[\"test\"]\n",
    "# filter for only examples which contain \"Gilmore_Girls\" in the File Name\n",
    "ds = ds.filter(lambda x: \"Gilmore\" in x[\"File Name\"])\n",
    "\n",
    "# Now let's prepare it for Lumigator upload. We need to rename some columns and delete the rest\n",
    "# rename the column \"input\" to \"text\" and \"output\" to \"ground_truth\". This is what Lumigator expects\n",
    "ds = ds.rename_column(\"Transcript\", \"examples\")\n",
    "ds = ds.rename_column(\"Recap\", \"ground_truth\")\n",
    "\n",
    "# remove all columns except \"text\" and \"ground_truth\"\n",
    "columns_list = ds.column_names\n",
    "columns_list.remove(\"examples\")\n",
    "columns_list.remove(\"ground_truth\")\n",
    "ds = ds.remove_columns(columns_list)\n",
    "\n",
    "print(f\"The filtered test split contains {len(ds)} examples.\")\n",
    "# convert ds to a csv and make it a string so we can upload it with the Lumigator API\n",
    "DS_OUTPUT = \"gg_dataset.csv\"\n",
    "ds.to_csv(DS_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset uploaded and has ID: 0fc03fef-5bce-4e79-9d72-e8a9440b214e\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from time import sleep\n",
    "\n",
    "from lumigator_schemas.datasets import DatasetFormat\n",
    "from lumigator_schemas.workflows import WorkflowCreateRequest, WorkflowStatus\n",
    "from lumigator_sdk.lumigator import LumigatorClient\n",
    "from lumigator_sdk.strict_schemas import ExperimentIdCreate\n",
    "\n",
    "\n",
    "# Now we'll create some helper functions.\n",
    "def wait_for_workflow_complete(lumi_client_int: LumigatorClient, workflow_id: str):\n",
    "    \"\"\"Wait for a workflow to complete.\"\"\"\n",
    "    workflow_details = lumi_client_int.workflows.get_workflow(workflow_id)\n",
    "    while workflow_details.status not in [WorkflowStatus.SUCCEEDED, WorkflowStatus.FAILED]:\n",
    "        sleep(5)\n",
    "        workflow_details = lumi_client_int.workflows.get_workflow(workflow_id)\n",
    "    return workflow_details\n",
    "\n",
    "\n",
    "# Time to connect up to the Lumigator client!\n",
    "LUMI_HOST = \"localhost:8000\"\n",
    "client = LumigatorClient(api_host=LUMI_HOST)\n",
    "\n",
    "# Upload that file that we created earlier\n",
    "with Path.open(DS_OUTPUT) as file:\n",
    "    data = file.read()\n",
    "dataset_response = client.datasets.create_dataset(dataset=data, format=DatasetFormat.JOB)\n",
    "dataset_id = dataset_response.id\n",
    "print(f\"Dataset uploaded and has ID: {dataset_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment created and has ID: 250565396489376488\n"
     ]
    }
   ],
   "source": [
    "# Now time to create an experiment in Lumigator! This is a container for all the workflows we'll run\n",
    "request = ExperimentIdCreate(\n",
    "    name=\"Gilmore Girls Summarization\",\n",
    "    description=\"Which LLM knows Rory and Lorelai the best?\",\n",
    ")\n",
    "experiment_response = client.experiments.create_experiment(request)\n",
    "experiment_id = experiment_response.id\n",
    "print(f\"Experiment created and has ID: {experiment_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "# Wait till the workflow is done\n",
    "def get_results(workflow_id):\n",
    "    print(f\"Waiting for workflow {workflow_id} to complete\")\n",
    "    details = wait_for_workflow_complete(client, workflow_id)\n",
    "    # Load the artifact so that we can look at the example\n",
    "    print(f\"Workflow {workflow_id} has completed\")\n",
    "    response = requests.get(details.artifacts_download_url)\n",
    "    result = response.json()\n",
    "\n",
    "    results = {\n",
    "        \"avg_rouge\": round(result[\"rouge\"][\"rouge2_mean\"], 2),\n",
    "        \"avg_bertscore\": round(result[\"bertscore\"][\"f1_mean\"], 2),\n",
    "        \"avg_meteor\": round(result[\"meteor\"][\"meteor_mean\"], 2),\n",
    "        \"predictions\": result[\"predictions\"],\n",
    "        \"ground_truth\": result[\"ground_truth\"],\n",
    "        \"examples\": result[\"examples\"],\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run the Deepseek R1 https://api-docs.deepseek.com/quick_start/pricing\n",
    "request = WorkflowCreateRequest(\n",
    "    name=\"Deepseek R1\",\n",
    "    description=\"Summarize with Deepseek R-1\",\n",
    "    model=\"deepseek/deepseek-reasoner\",\n",
    "    model_url=\"deepseek/deepseek-reasoner\",\n",
    "    dataset=dataset_id,\n",
    "    experiment_id=experiment_id,\n",
    "    max_samples=1,\n",
    ")\n",
    "deepseek_response = client.workflows.create_workflow(request)\n",
    "deepseek_id = deepseek_response.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's run the same thing, but with GPT-40\n",
    "request = WorkflowCreateRequest(\n",
    "    name=\"GPT-40\",\n",
    "    description=\"Summarize with GPT-40\",\n",
    "    model=\"gpt-4o\",\n",
    "    model_url=\"gpt-4o\",\n",
    "    dataset=dataset_id,\n",
    "    experiment_id=experiment_id,\n",
    "    max_samples=1,\n",
    ")\n",
    "gpt4_response = client.workflows.create_workflow(request)\n",
    "gpt4_id = gpt4_response.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for workflow 8338c0686462470e9d68c36b1dd5dd66 to complete\n",
      "Workflow 8338c0686462470e9d68c36b1dd5dd66 has completed\n",
      "Waiting for workflow 7ccca9a2ccfc4c61bf8f8a98cbc737ea to complete\n",
      "Workflow 7ccca9a2ccfc4c61bf8f8a98cbc737ea has completed\n"
     ]
    }
   ],
   "source": [
    "# for each one, wait til they're done and then grab the resuls\n",
    "deepseek_results = get_results(deepseek_id)\n",
    "gpt4_results = get_results(gpt4_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Rouge-2 Scores\n",
      "Deepseek R1: 0.03\n",
      "GPT-40: 0.03\n",
      "==========\n",
      "==========\n",
      "BertScore Scores\n",
      "Deepseek R1: 0.82\n",
      "GPT-40: 0.81\n",
      "==========\n",
      "==========\n",
      "Meteor Scores\n",
      "Deepseek R1: 0.19\n",
      "GPT-40: 0.24\n",
      "==========\n",
      "==========\n",
      "Deepseek R1\n",
      "==========\n",
      "**Summary of \"Gilmore Girls: Concert Interruptus\" (Season 1, Episode 13):**\n",
      "\n",
      "Lorelai and Rory prepare for a town charity rummage sale, clashing over Lorelaiâ€™s sentimental attachment to her eccentric wardrobe (e.g., a tasseled halter top). Meanwhile, Sookie secures coveted tickets to a Bangles concert, prompting Lorelai to invite Rory, Lane, and Sookie. Laneâ€™s strict mother, Mrs. Kim, forbids her from attending, highlighting their generational and cultural conflict.  \n",
      "\n",
      "At Chilton, Roryâ€™s debate team (with Paris, Madeline, and Louise) studies at the Gilmore house, showcasing Parisâ€™s intensity and Roryâ€™s efforts to navigate high school dynamics. Lorelai impulsively offers the girls her concert tickets, sacrificing her front-row seats to foster Roryâ€™s social connections.  \n",
      "\n",
      "During the concert, Madeline and Louise recklessly leave with strangers, forcing Lorelai and Sookie to rescue them in New York, underscoring Lorelaiâ€™s protective motherhood. Rory bonds with Paris, who reveals vulnerability about her crush on Tristin.  \n",
      "\n",
      "Back in Stars Hollow, the rummage sale reveals Lukeâ€™s unresolved feelings for his ex, Rachel, when Lorelai returns a sweatshirt heâ€™d kept. The episode closes with humor and heart, emphasizing Lorelai and Roryâ€™s tight-knit relationship, Lukeâ€™s quiet nostalgia, and the townâ€™s quirky community spirit.  \n",
      "\n",
      "**Themes**: Family bonds, teenage rebellion, selflessness, and the blend of humor and heartfelt moments central to Stars Hollow life.\n",
      "==========\n",
      "GPT-40\n",
      "==========\n",
      "In the episode \"Concert Interruptus,\" Lorelai and Rory prepare to contribute items to a charity rummage sale. Lorelai struggles to part with some of her clothing, including a rhinestone and zebra-striped halter top. Rory encourages her because Lorelai is helping to organize and run the sale.\n",
      "\n",
      "The episode also features a subplot at Chilton, Roryâ€™s school, where students are assigned to teams for an upcoming debate. Paris is on Rory's team, and they agree to meet at Rory's house for study. Lorelai offers her concert tickets to Rory and her classmates as a goodwill gesture, attempting to help Rory build friendships. Paris, initially hesitant, decides to attend.\n",
      "\n",
      "At the concert, Louise and Madeline leave early with boys they met, which concerns Rory. Lorelai and Sookie, who have purchased additional seats, are informed and decide to retrieve them, insisting on everyone's safety. Meanwhile, there's discussion about Luke's past serious relationship with a woman named Rachel, whose belongings accidentally ended up in the rummage sale.\n",
      "\n",
      "The next day at the rummage sale, Lorelai and Luke reconcile after a small misunderstanding over the sale item tied to his ex-girlfriend. Rory's relationships with her schoolmates evolve positively as she navigates her new social environment.\n"
     ]
    }
   ],
   "source": [
    "# All Done! Let's print out a few results\n",
    "print(\"=\" * 10)\n",
    "print(\"Rouge-2 Scores\")\n",
    "print(f\"Deepseek R1: {deepseek_results['avg_rouge']}\")\n",
    "print(f\"GPT-40: {gpt4_results['avg_rouge']}\")\n",
    "print(\"=\" * 10)\n",
    "\n",
    "print(\"=\" * 10)\n",
    "print(\"BertScore Scores\")\n",
    "print(f\"Deepseek R1: {deepseek_results['avg_bertscore']}\")\n",
    "print(f\"GPT-40: {gpt4_results['avg_bertscore']}\")\n",
    "print(\"=\" * 10)\n",
    "\n",
    "print(\"=\" * 10)\n",
    "print(\"Meteor Scores\")\n",
    "print(f\"Deepseek R1: {deepseek_results['avg_meteor']}\")\n",
    "print(f\"GPT-40: {gpt4_results['avg_meteor']}\")\n",
    "print(\"=\" * 10)\n",
    "\n",
    "# print the first example\n",
    "print(\"=\" * 10)\n",
    "print(\"Deepseek R1\")\n",
    "print(\"=\" * 10)\n",
    "print(deepseek_results[\"predictions\"][0][\"choices\"][0][\"message\"][\"content\"])\n",
    "print(\"=\" * 10)\n",
    "print(\"GPT-40\")\n",
    "print(\"=\" * 10)\n",
    "print(gpt4_results[\"predictions\"][0][\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "At least for summarizing Gilmore Girls Episodes, the hype about Deepseek-R1 looks like it's real. \n",
    "\n",
    "The quality of the summary rivals GPT-4o not only in terms of automatic metrics like ROUGE/METEOR/BERTSCORE, but a manual comparison confirms that they are similarly comprehensive."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
