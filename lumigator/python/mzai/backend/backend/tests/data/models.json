{
    "total": 6,
    "items": [
      {
        "name": "facebook/bart-large-cnn",
        "uri": "hf://facebook/bart-large-cnn",
        "description": "BART is a large-sized model fine-tuned on the CNN Daily Mail dataset.",
        "requirements": [],
        "info": {
          "parameter_count": "406M",
          "tensor_type": "F32",
          "model_size": "1.63GB"
        },
        "tasks": [
          {
            "summarization": {
              "max_length": 142,
              "min_length": 56,
              "length_penalty": 2,
              "early_stopping": true,
              "no_repeat_ngram_size": 3,
              "num_beams": 4
            }
          }
        ]
      },
      {
        "name": "Falconsai/text_summarization",
        "uri": "hf://Falconsai/text_summarization",
        "description": "A fine-tuned variant of the T5 transformer model, designed for the task of text summarization.",
        "requirements": [],
        "info": {
          "parameter_count": "60.5M",
          "tensor_type": "F32",
          "model_size": "242MB"
        },
        "tasks": [
          {
            "summarization": {
              "max_length": 200,
              "min_length": 30,
              "length_penalty": 2,
              "early_stopping": true,
              "no_repeat_ngram_size": 3,
              "num_beams": 4
            }
          }
        ]
      },
      {
        "name": "gpt-4o-mini",
        "uri": "oai://gpt-4o-mini",
        "description": "OpenAI's GPT-4o-mini model.",
        "requirements": [ "api_key" ],
        "info": null,
        "tasks": [
          {
            "summarization": null
          }
        ]
      },
      {
        "name": "gpt-4o",
        "uri": "oai://gpt-4o",
        "description": "OpenAI's GPT-4o model.",
        "requirements": [ "api_key" ],
        "info": null,
        "tasks": [
          {
            "summarization": null
          }
        ]
      },
      {
        "name": "open-mistral-7b",
        "uri": "mistral://open-mistral-7b",
        "description": "Mistral's 7B model.",
        "requirements": [ "api_key" ],
        "info": null,
        "tasks": [
          {
            "summarization": null
          }
        ]
      },
      {
        "name": "mistralai/Mistral-7B-Instruct-v0.2",
        "uri": "llamafile://mistralai/Mistral-7B-Instruct-v0.2",
        "description": "A llamafile package of Mistral's 7B Instruct model.",
        "requirements": [ "llamafile" ],
        "info": {
          "parameter_count": "7.24B",
          "tensor_type": "BF16",
          "model_size": "14.5GB"
        },
        "tasks": [
          {
            "summarization": null
          }
        ]
      }
    ]
  }
