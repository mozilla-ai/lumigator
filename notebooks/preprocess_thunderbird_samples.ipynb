{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34b10468c24e464",
   "metadata": {},
   "source": [
    "## Generating Data for Ground Truth Evaluation\n",
    "\n",
    "In order to generate a ground truth summary for our data, we first need an input dataset. In this case we use threads from the [Thunderbird public mailing list.](https://thunderbird.topicbox.com/latest).  In order to generate the ground truth and then later evaluate the model, we need at least 100 samples to start with, where a sample is a single email or single email conversation.\n",
    "\n",
    "Our selection criteria: \n",
    "\n",
    "+ Collect 100 samples of email thread conversations, as recent as possible and fairly complete so they can be evaluated\n",
    "+ Clean them of email formatting such as `>`\n",
    "+ One consideration here will be that BART, the baseline model we're using, accepts 1024 token context window as input, i.e.  we have to have input email threads that are ~ approximately 1000 words, so keeping on the conservative side\n",
    "\n",
    "Once we've collected them, we'd like to take a look at the data before we generate summaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T16:57:48.906365Z",
     "start_time": "2024-07-23T16:57:48.854190Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# wrap columns for inspection\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "# stylesheet for visibility\n",
    "plt.style.use(\"fast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d69f944bbc60623",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T16:58:46.328746Z",
     "start_time": "2024-07-23T16:58:46.320569Z"
    }
   },
   "outputs": [],
   "source": [
    "APP_URL = os.environ.get('APP_URL')\n",
    "LOCAL_APP_URL = os.environ.get('LOCAL_APP_URL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a74a337b7154a69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T16:58:46.988109Z",
     "start_time": "2024-07-23T16:58:46.711768Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_id = \"db7ff8c2-a255-4d75-915d-77ba73affc53\"\n",
    "r = requests.get(f\"{APP_URL}/api/v1/datasets/{dataset_id}\")\n",
    "print(json.dumps(r.json(), indent = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2df1feb201ecdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T16:58:50.527831Z",
     "start_time": "2024-07-23T16:58:50.497404Z"
    }
   },
   "outputs": [],
   "source": [
    "# load into pandas\n",
    "df = pd.read_csv('thunderbird_samples.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffd209a84f8adca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T16:58:51.787656Z",
     "start_time": "2024-07-23T16:58:51.780912Z"
    }
   },
   "outputs": [],
   "source": [
    "# Examine a single sample \n",
    "# we define the data with examples\n",
    "df['examples'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fdbd835dfebc7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T16:58:54.803600Z",
     "start_time": "2024-07-23T16:58:54.792770Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add a function to do some simple character counts for model input\n",
    "\n",
    "df['char_count'] = df['examples'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c561afd9df71b43b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T16:58:55.417580Z",
     "start_time": "2024-07-23T16:58:55.400401Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show dataframe \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a3fdf6c44677f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T18:41:18.404970Z",
     "start_time": "2024-07-23T18:41:18.397507Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess data \n",
    "df['preprocessed'] = df['examples'].apply(lambda x: x.replace(\"'\", \"\").lower().strip())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129fe6c99d619a53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T16:58:57.529483Z",
     "start_time": "2024-07-23T16:58:57.523188Z"
    }
   },
   "outputs": [],
   "source": [
    "df['char_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767546faef15d9f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T16:58:58.440667Z",
     "start_time": "2024-07-23T16:58:58.309946Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot character counts \n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.hist(df['char_count'], bins=30)\n",
    "ax.set_xlabel('Character Count')\n",
    "ax.set_ylabel('Frequency')\n",
    "\n",
    "stats = df['char_count'].describe().apply(lambda x: f\"{x:.0f}\")\n",
    "\n",
    "# Add text boxes for statistics\n",
    "plt.text(1.05, 0.95, stats.to_string(), \n",
    "         transform=ax.transAxes, verticalalignment='top')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(right=0.75)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a04b32fb9cdf20",
   "metadata": {},
   "source": [
    "We can see from the chart that about half of our email threads are on the shorter side, however 50% are more than 1300 characters which may be an issue for the model. Something to watch out for as we begin to run inference runs. If we wanted to be precise, we could tokenize each row with the [BART tokenizer](https://huggingface.co/docs/transformers/en/model_doc/bart#transformers.BartTokenizer)020 to get true counts input into the model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e30ef8c01bbedb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:07:10.321639Z",
     "start_time": "2024-07-23T18:44:49.128371Z"
    }
   },
   "outputs": [],
   "source": [
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "def remove_single_quotes(text):\n",
    "    return text.replace(\"'\", \"\")\n",
    "\n",
    "responses = []\n",
    "\n",
    "# generate 10 instances of ground truth \n",
    "for string in df['preprocessed'][0:10]:\n",
    "    response = requests.post(f\"{APP_URL}/api/v1/ground-truth/deployments/97fd0628-e9b6-49e9-9a67-f36bab0fb3aa\", headers=headers, data=json.dumps({\"text\": string}))\n",
    "    print(string, response.text)\n",
    "    responses.append((string, response.text))\n",
    "\n",
    "results_df = pd.DataFrame(responses, columns=['Original', 'Response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c750e470ad9dbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:07:10.336475Z",
     "start_time": "2024-07-23T19:07:10.325142Z"
    }
   },
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcee2472f0794a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:51:00.329961Z",
     "start_time": "2024-07-23T19:51:00.320232Z"
    }
   },
   "outputs": [],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e0992af506ff0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:56:47.644148Z",
     "start_time": "2024-07-23T19:56:47.632747Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "# Function to extract the result value from the JSON string\n",
    "def extract_result(json_string):\n",
    "    try:\n",
    "        return json.loads(json_string)['deployment_response']['result']\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "# Create the DataFrame\n",
    "responses_clean = pd.DataFrame(responses, columns=['first_value', 'json_string'])\n",
    "responses_clean['result'] = responses_clean['json_string'].apply(extract_result)\n",
    "\n",
    "# Drop the intermediate 'json_string' column\n",
    "responses_clean = responses_clean[['first_value', 'result']]\n",
    "\n",
    "print(responses_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a909be0e8c522de8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T19:58:11.696990Z",
     "start_time": "2024-07-23T19:58:11.675954Z"
    }
   },
   "outputs": [],
   "source": [
    "responses_clean.to_csv('output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
