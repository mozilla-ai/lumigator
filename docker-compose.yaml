name: lumigator

services:

  localstack:
    # if you want to enable local S3-style data persistence, use the following
    # image and set LOCALSTACK_AUTH_TOKEN in your env
    # image: localstack/localstack-pro:3.4.0
    image: localstack/localstack:3.4.0
    platform: linux/amd64
    ports:
      - 4566:4566
    environment:
      - SERVICES=s3:4566
      - CREATE_BUCKETS=lumigator-storage
      - LOCALSTACK_AUTH_TOKEN=${LOCALSTACK_AUTH_TOKEN}
      - PERSISTENCE=1
      - SNAPSHOT_SAVE_STRATEGY=ON_REQUEST
      - EXTRA_CORS_ALLOWED_ORIGINS=*
    volumes:
      - localstack-data:/var/lib/localstack
    profiles:
      - local

  localstack-create-bucket:
    image: localstack/localstack:3.4.0
    platform: linux/amd64
    depends_on:
      localstack:
        condition: service_healthy
    entrypoint: >
       bash -c "awslocal s3 mb s3://lumigator-storage"
    extra_hosts:
      - "localhost:host-gateway"
    profiles:
      - local

  ray:
    image: rayproject/ray:2.30.0-py311-cpu${RAY_ARCH_SUFFIX}
    ports:
      - "6379:6379"
      - "8265:8265"
      - "10001:10001"
    command: bash -c "ray start --head --dashboard-port=8265 --port=6379 --dashboard-host=0.0.0.0 --redis-password=yourpassword --block" # pragma: allowlist secret
    shm_size: 2g
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: '5g'
    environment:
      - HOST=localhost
      - RAY_IMAGE=raytest
      - REDISPORT=6379
      - DASHBOARDPORT=8265
      - HEADNODEPORT=10001
      - REDISPASSWORD=yourpassword
      - NUM_WORKERS=4
      - NUM_CPU_WORKER=1
      # LOCAL_FSSPEC_S3 env vars required by s3fs running inside evaluator ray jobs
      - LOCAL_FSSPEC_S3_ENDPOINT_URL=${AWS_ENDPOINT_URL} # Should match AWS_ENDPOINT_URL
      - LOCAL_FSSPEC_S3_KEY=${AWS_ACCESS_KEY_ID} # Should match AWS_SECRET_ACCESS_KEY
      - LOCAL_FSSPEC_S3_SECRET=${AWS_SECRET_ACCESS_KEY} # Should match AWS_SECRET_ACCESS_KEY
      - MISTRAL_API_KEY=${MISTRAL_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - HF_TOKEN=${HF_TOKEN}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}
      - AWS_ENDPOINT_URL=${AWS_ENDPOINT_URL}

    # NOTE: to keep AWS_ENDPOINT_URL as http://localhost:4566 both on the host system
    #       and inside containers, we map localhost to the host gateway IP.
    #       This currently works properly, but might be the cause of networking
    #       issues down the line. This should be used only for local, development
    #       deployments.
    extra_hosts:
      - "localhost:host-gateway"
    profiles:
      - local

  backend:
    image: mzdotai/lumigator:latest
    build:
      context: .
      dockerfile: "Dockerfile"
      target: "main_image"
    platform: linux/amd64
    depends_on:
      localstack:
        condition: "service_started"
        required: false
      ray:
        condition: "service_started"
        required: false
    ports:
      - 8000:8000
    environment:
      - DEPLOYMENT_TYPE=local
      # The local file needs to be available through a mount,
      # if persistence is needed
      - SQLALCHEMY_DATABASE_URL=sqlite:///local.db
      - S3_ENDPOINT_URL=${AWS_ENDPOINT_URL}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}
      - AWS_ENDPOINT_URL=${AWS_ENDPOINT_URL}
      - S3_BUCKET=${S3_BUCKET}
      - PYTHONPATH=/mzai/lumigator/python/mzai/backend
      - EVALUATOR_PIP_REQS=/mzai/lumigator/python/mzai/jobs/evaluator/requirements.txt
      - EVALUATOR_WORK_DIR=/mzai/lumigator/python/mzai/jobs/evaluator
      - INFERENCE_PIP_REQS=/mzai/lumigator/python/mzai/jobs/inference/requirements.txt
      - INFERENCE_WORK_DIR=/mzai/lumigator/python/mzai/jobs/inference
      - RAY_DASHBOARD_PORT=${RAY_DASHBOARD_PORT}
      - RAY_HEAD_NODE_HOST=${RAY_HEAD_NODE_HOST}
      - MISTRAL_API_KEY=${MISTRAL_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - RAY_WORKER_GPUS=0
      - RAY_WORKER_GPUS_FRACTION=0
      - LUMI_API_CORS_ALLOWED_ORIGINS=${LUMI_API_CORS_ALLOWED_ORIGINS}
    # NOTE: to keep AWS_ENDPOINT_URL as http://localhost:4566 both on the host system
    #       and inside containers, we map localhost to the host gateway IP.
    #       This currently works properly, but might be the cause of networking
    #       issues down the line. This should be used only for local, development
    #       deployments.
    extra_hosts:
      - "localhost:host-gateway"

  frontend:
    image: mzdotai/lumigator-frontend:latest
    build:
      context: .
      dockerfile: "./lumigator/frontend/Dockerfile"
      target: "server"
      args:
       VUE_APP_BASE_URL: ${VUE_APP_BASE_URL}
    depends_on:
      backend:
        condition: "service_started"
        required: true
    ports:
      - 80:80

volumes:

    localstack-data:
    database_volume:
