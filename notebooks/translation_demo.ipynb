{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4965a253-ff2e-4925-97bb-4e6a24481666",
   "metadata": {},
   "source": [
    "# Demo of Translation Use Case with Lumigator SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3652ddd9",
   "metadata": {},
   "source": [
    "### Lumigator Client\n",
    "Check if client is up and running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67dc9899-abbe-4ae7-8352-fdfd77acbf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lumigator_sdk.lumigator import LumigatorClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86bbf498-70e1-4e6f-9a3d-5c201fb7fea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection is: OK\n"
     ]
    }
   ],
   "source": [
    "LUMI_HOST = \"localhost:8000\"\n",
    "client = LumigatorClient(api_host=LUMI_HOST)\n",
    "print(f\"Connection is: {client.health.healthcheck().status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd504a65",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "Using `Helsinki-NLP/opus-100` en-es dataset from Huggingface Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d48e754-41ed-4fb4-9650-af1b8538e16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a26aa546-48d9-437c-a338-aaaea5e1584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Helsinki-NLP/opus-100\", \"en-es\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "412a53c6-ed38-4d6a-a26d-2e0e6c5b8987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2000 validation pairs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I don't even remember what the fight was about.</td>\n",
       "      <td>No recuerdo por qué fue la pelea.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Here are the sites of each of those that have ...</td>\n",
       "      <td>Estos son los sitios en que cada Congreso ha t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm the man who killed Blackbeard.</td>\n",
       "      <td>Sí. Soy el hombre que mató a Barbanegra.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Don't get smart.</td>\n",
       "      <td>No te hagas el inteligente.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is there an exact moment in the life of a sold...</td>\n",
       "      <td>¿Existe un límite de cuándo se padece y cuándo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  en  \\\n",
       "0    I don't even remember what the fight was about.   \n",
       "1  Here are the sites of each of those that have ...   \n",
       "2                 I'm the man who killed Blackbeard.   \n",
       "3                                   Don't get smart.   \n",
       "4  Is there an exact moment in the life of a sold...   \n",
       "\n",
       "                                                  es  \n",
       "0                  No recuerdo por qué fue la pelea.  \n",
       "1  Estos son los sitios en que cada Congreso ha t...  \n",
       "2           Sí. Soy el hombre que mató a Barbanegra.  \n",
       "3                        No te hagas el inteligente.  \n",
       "4  ¿Existe un límite de cuándo se padece y cuándo...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_translation = pd.DataFrame(dataset[\"translation\"])\n",
    "df_translation.columns = [\"en\", \"es\"]\n",
    "print(f\"Loaded {len(df_translation)} validation pairs\")\n",
    "df_translation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f67ab2e-4be3-4430-9ceb-46e25db12fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns to examples and ground_truth\n",
    "df_translation = df_translation.rename(columns={\"en\": \"examples\", \"es\": \"ground_truth\"})\n",
    "filename = \"translation_en_es.csv\"\n",
    "df_translation = df_translation.sample(10)\n",
    "df_translation.to_csv(filename, index=False)  # Save the file locally with 10 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f70acd",
   "metadata": {},
   "source": [
    "### Upload Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e26ae289-3cca-4805-ab42-3518235c21c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset uploaded and has ID: 5b8188b9-1217-4cab-b9d2-cbd3fdbea9a1\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from lumigator_schemas.datasets import DatasetFormat\n",
    "\n",
    "# Upload that file that we created earlier\n",
    "with Path.open(Path(filename), \"r\") as file:\n",
    "    data = file.read()\n",
    "dataset_response = client.datasets.create_dataset(dataset=data, format=DatasetFormat.JOB)\n",
    "dataset_id = dataset_response.id\n",
    "print(f\"Dataset uploaded and has ID: {dataset_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db30aee",
   "metadata": {},
   "source": [
    "### Create Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80bdca29-2436-48a8-bdb0-cbd19631bafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment created and has ID: 2\n"
     ]
    }
   ],
   "source": [
    "from lumigator_schemas.experiments import ExperimentCreate\n",
    "\n",
    "# Task as translation with necessary params\n",
    "task_definition = {\n",
    "    \"task\": \"translation\",\n",
    "    \"source_language\": \"English\",\n",
    "    \"target_language\": \"Spanish\",\n",
    "}\n",
    "max_samples = 5\n",
    "\n",
    "request = ExperimentCreate(\n",
    "    name=\"Translation Experiment EN to ES\",\n",
    "    description=\"With Opus-NLP dataset\",\n",
    "    dataset=dataset_id,\n",
    "    task_definition=task_definition,\n",
    "    max_samples=max_samples,\n",
    ")\n",
    "\n",
    "experiment_response = client.experiments.create_experiment(request)\n",
    "experiment_id = experiment_response.id\n",
    "print(f\"Experiment created and has ID: {experiment_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11fccdc",
   "metadata": {},
   "source": [
    "### Create and Run Workflows\n",
    "- One with Open AI GPT-4o-mini\n",
    "- One with Mistral-7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2286c5e1-71e5-45c5-8554-811dcdc65e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created workflow Translation with gpt-4o-mini with ID 0d4a304e900b413796d5e6a559b13525 for model gpt-4o-mini\n",
      "Created workflow Translation with open-mistral-7b with ID eb49365aee7544cf8d0e312465eeea34 for model open-mistral-7b\n"
     ]
    }
   ],
   "source": [
    "from lumigator_schemas.workflows import WorkflowCreateRequest\n",
    "\n",
    "custom_system_prompt = \"\"\"\n",
    "You are an expert in English and Spanish. \n",
    "Please provide a high-quality translation of the following text from English to Spanish.\n",
    "Only generate the translated text. No additional text or explanation needed.\n",
    "\"\"\"\n",
    "\n",
    "configurations = [\n",
    "    # OpenAI GPt-4o-mini no explicit system prompt - uses default under the hood\n",
    "    {\"name\": \"Translation with gpt-4o-mini\", \"model\": \"gpt-4o-mini\", \"provider\": \"openai\"},\n",
    "    # Mistral 7B with custom system prompt\n",
    "    {\n",
    "        \"name\": \"Translation with open-mistral-7b\",\n",
    "        \"model\": \"open-mistral-7b\",\n",
    "        \"provider\": \"mistral\",\n",
    "        \"system_prompt\": custom_system_prompt,\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "for config in configurations:\n",
    "    params = {\n",
    "        \"name\": config[\"name\"],\n",
    "        \"model\": config[\"model\"],\n",
    "        \"provider\": config[\"provider\"],\n",
    "        \"dataset\": dataset_id,\n",
    "        \"experiment_id\": experiment_id,\n",
    "        \"task_definition\": task_definition,\n",
    "        \"max_samples\": max_samples,\n",
    "    }\n",
    "    params.update(config)\n",
    "    request = WorkflowCreateRequest(**params)\n",
    "    created_workflow = client.workflows.create_workflow(request)\n",
    "    print(f\"Created workflow {created_workflow.name} with ID {created_workflow.id} for model {created_workflow.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30648699",
   "metadata": {},
   "source": [
    "### Models Endpoint\n",
    "- List models supported for task(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e0d0847-2a33-4dfb-bdc8-af7b1940a64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-mini\n",
      "gpt-4o\n",
      "deepseek-reasoner\n",
      "deepseek-chat\n",
      "open-mistral-7b\n",
      "mistralai/Mistral-7B-Instruct-v0.2\n"
     ]
    }
   ],
   "source": [
    "### Get the list of models supported for translation\n",
    "models_response = client.models.get_suggested_models(tasks=[\"translation\"])\n",
    "for model_config in models_response.items:\n",
    "    print(model_config.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c158861b-9e47-4c85-b385-e2db63807832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46287a01-735c-4b32-b083-a219d7e53473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lumigator-notebook",
   "language": "python",
   "name": "lumigator-notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
